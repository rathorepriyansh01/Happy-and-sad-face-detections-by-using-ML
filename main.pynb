
Open In Colab

import kagglehub

# Download latest version
path = kagglehub.dataset_download("aravindanr22052001/emotiondetection-happy-or-sad")

print("Path to dataset files:", path)
     
Downloading from https://www.kaggle.com/api/v1/datasets/download/aravindanr22052001/emotiondetection-happy-or-sad?dataset_version_number=1...
100%|██████████| 64.8M/64.8M [00:00<00:00, 211MB/s]
Extracting files...
Path to dataset files: /root/.cache/kagglehub/datasets/aravindanr22052001/emotiondetection-happy-or-sad/versions/1

import tensorflow as tf
from tensorflow.keras import layers, models, Input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import Callback
from tensorflow import keras
     

directory ='/kaggle/input/emotiondetection-happy-or-sad/data/'
     

class MyCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if (logs.get('accuracy') and logs.get('accuracy')>=0.81) :
            print('\n reached 81 % accuracy so counceling training')
            self.model.stop_training = True

callback = MyCallback()
     

model= tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3,3),padding='same',activation='relu', input_shape=(256,256,3)),
    tf.keras.layers.MaxPooling2D(2),
    tf.keras.layers.Conv2D(32, (3,3),padding='same',activation='relu'),
    tf.keras.layers.MaxPooling2D(2),
    tf.keras.layers.Conv2D(64, (3,3),padding='same',activation='relu'),
    tf.keras.layers.MaxPooling2D(2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
     
/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)

model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'] )
     

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1.0/255,
                                   validation_split=0.2,
                                    rotation_range=20,
                                    zoom_range=0.2,
                                    width_shift_range=0.2,
                                    height_shift_range=0.2,
                                    horizontal_flip=True)

train_generator = train_datagen.flow_from_directory('/root/.cache/kagglehub/datasets/aravindanr22052001/emotiondetection-happy-or-sad/versions/1/data',
        subset='training',
        target_size=(256, 256),
        batch_size=8,
        class_mode='binary')

val_generator = train_datagen.flow_from_directory('/root/.cache/kagglehub/datasets/aravindanr22052001/emotiondetection-happy-or-sad/versions/1/data',
        subset='validation',
        target_size=(256, 256),
        batch_size=8,
        class_mode='binary')
     
Found 134 images belonging to 2 classes.
Found 33 images belonging to 2 classes.

history = model.fit(
        train_generator,
        steps_per_epoch=4,
        epochs=50,
        validation_data =val_generator,
        verbose=1,
        callbacks=[callback])
     
/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
Epoch 1/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 11s 2s/step - accuracy: 0.6375 - loss: 1.9745 - val_accuracy: 0.5455 - val_loss: 0.7366
Epoch 2/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 7s 2s/step - accuracy: 0.6042 - loss: 0.7111 - val_accuracy: 0.5455 - val_loss: 0.6792
Epoch 3/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 6s 2s/step - accuracy: 0.5750 - loss: 0.6631 - val_accuracy: 0.4545 - val_loss: 0.7005
Epoch 4/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 8s 2s/step - accuracy: 0.4292 - loss: 0.7097 - val_accuracy: 0.4545 - val_loss: 0.7062
Epoch 5/50
1/4 ━━━━━━━━━━━━━━━━━━━━ 2s 796ms/step - accuracy: 0.5000 - loss: 0.6786
/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
4/4 ━━━━━━━━━━━━━━━━━━━━ 3s 752ms/step - accuracy: 0.5000 - loss: 0.6786 - val_accuracy: 0.4545 - val_loss: 0.7012
Epoch 6/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 7s 2s/step - accuracy: 0.4083 - loss: 0.7079 - val_accuracy: 0.6970 - val_loss: 0.6819
Epoch 7/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 7s 2s/step - accuracy: 0.5475 - loss: 0.6853 - val_accuracy: 0.5152 - val_loss: 0.7081
Epoch 8/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 9s 3s/step - accuracy: 0.4917 - loss: 0.6817 - val_accuracy: 0.5758 - val_loss: 0.6763
Epoch 9/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 6s 2s/step - accuracy: 0.5417 - loss: 0.6736 - val_accuracy: 0.5455 - val_loss: 0.6740
Epoch 10/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 4s 982ms/step - accuracy: 0.5000 - loss: 0.6804 - val_accuracy: 0.5455 - val_loss: 0.6756
Epoch 11/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 16s 2s/step - accuracy: 0.4458 - loss: 0.7165 - val_accuracy: 0.6061 - val_loss: 0.6694
Epoch 12/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 6s 2s/step - accuracy: 0.6375 - loss: 0.6631 - val_accuracy: 0.6364 - val_loss: 0.6614
Epoch 13/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 8s 2s/step - accuracy: 0.6655 - loss: 0.6527 - val_accuracy: 0.6970 - val_loss: 0.6447
Epoch 14/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 6s 2s/step - accuracy: 0.7417 - loss: 0.5979 - val_accuracy: 0.6667 - val_loss: 0.6229
Epoch 15/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 4s 1s/step - accuracy: 0.6250 - loss: 0.6199 - val_accuracy: 0.6970 - val_loss: 0.6312
Epoch 16/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 17s 2s/step - accuracy: 0.6625 - loss: 0.6286 - val_accuracy: 0.6667 - val_loss: 0.6041
Epoch 17/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 6s 2s/step - accuracy: 0.8208 - loss: 0.4955 - val_accuracy: 0.6667 - val_loss: 0.6745
Epoch 18/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 7s 2s/step - accuracy: 0.7008 - loss: 0.5224 - val_accuracy: 0.5758 - val_loss: 0.7691
Epoch 19/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 9s 3s/step - accuracy: 0.5417 - loss: 0.7885 - val_accuracy: 0.6364 - val_loss: 0.6337
Epoch 20/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 3s 756ms/step - accuracy: 0.2500 - loss: 0.8764 - val_accuracy: 0.6970 - val_loss: 0.6094
Epoch 21/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 14s 2s/step - accuracy: 0.7250 - loss: 0.5926 - val_accuracy: 0.6970 - val_loss: 0.6165
Epoch 22/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 7s 2s/step - accuracy: 0.8292 - loss: 0.6245 - val_accuracy: 0.5758 - val_loss: 0.6329
Epoch 23/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 6s 2s/step - accuracy: 0.6414 - loss: 0.5944 - val_accuracy: 0.7273 - val_loss: 0.5567
Epoch 24/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 8s 2s/step - accuracy: 0.6958 - loss: 0.5482 - val_accuracy: 0.6667 - val_loss: 0.5595
Epoch 25/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 3s 748ms/step - accuracy: 0.3750 - loss: 0.8343 - val_accuracy: 0.6667 - val_loss: 0.5650
Epoch 26/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 7s 2s/step - accuracy: 0.6250 - loss: 0.4879 - val_accuracy: 0.6970 - val_loss: 0.4906
Epoch 27/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 7s 2s/step - accuracy: 0.7708 - loss: 0.5513 - val_accuracy: 0.7576 - val_loss: 0.5045
Epoch 28/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 7s 2s/step - accuracy: 0.7833 - loss: 0.4422 - val_accuracy: 0.7576 - val_loss: 0.4947
Epoch 29/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 6s 2s/step - accuracy: 0.5383 - loss: 0.7479 - val_accuracy: 0.6970 - val_loss: 0.5176
Epoch 30/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 3s 854ms/step - accuracy: 0.6250 - loss: 0.4678 - val_accuracy: 0.6970 - val_loss: 0.5083
Epoch 31/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 7s 2s/step - accuracy: 0.6542 - loss: 0.5512 - val_accuracy: 0.7273 - val_loss: 0.5243
Epoch 32/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 9s 3s/step - accuracy: 0.7958 - loss: 0.5697 - val_accuracy: 0.6667 - val_loss: 0.5326
Epoch 33/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 6s 2s/step - accuracy: 0.7625 - loss: 0.4373 - val_accuracy: 0.7273 - val_loss: 0.4932
Epoch 34/50
4/4 ━━━━━━━━━━━━━━━━━━━━ 7s 2s/step - accuracy: 0.6664 - loss: 0.5286 - val_accuracy: 0.7576 - val_loss: 0.5010
Epoch 35/50
1/4 ━━━━━━━━━━━━━━━━━━━━ 2s 820ms/step - accuracy: 1.0000 - loss: 0.4072
 reached 81 % accuracy so counceling training
4/4 ━━━━━━━━━━━━━━━━━━━━ 3s 730ms/step - accuracy: 1.0000 - loss: 0.4072 - val_accuracy: 0.6970 - val_loss: 0.5016

import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()


plt.show()
     

<Figure size 640x480 with 0 Axes>
